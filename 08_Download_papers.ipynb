{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c144ee-ade6-44e3-b9ef-1e1459d42760",
   "metadata": {},
   "source": [
    "## Download papers\n",
    "\n",
    "Download the full texts of the review papers on machine learning, identified in notebook 05_benchmark_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3a13e93-9a9e-4458-8846-77bfaca4d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import os\n",
    "import tempfile\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453448d7-6534-465a-817a-e97a4ec1836d",
   "metadata": {},
   "source": [
    "### Load the metadata \n",
    "From the review articles on machine learning identified in 05_benchmark_articles notebook. Keep only the abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77561c93-6a0f-4786-89df-1b29424e7fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.45 ms, sys: 346 µs, total: 5.8 ms\n",
      "Wall time: 5.84 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load metadata extracted data in notebook 00_load_metadata\n",
    "arxiv_ml_reviews = pd.read_csv('data/arxiv_ml_reviews.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "364700db-8fcc-49f3-a4af-11fe8fc4ace7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 110 review articles on machine learning in the dataset\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {arxiv_ml_reviews.shape[0]} review articles on machine learning in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9089e573-727a-4c36-8d7d-43a9060bee8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001.11017"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_ml_reviews.iloc[10].arxiv_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462300e6-e23a-4c40-a252-820c7c8b1aad",
   "metadata": {},
   "source": [
    "## Download all files\n",
    "* loop through arxiv_ml_reviews\n",
    "* get the arxiv id for each review paper\n",
    "* download the paper to the fulltexts dir\n",
    "* clean the dataframe by droping papers thatdo not have a full text\n",
    "* save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ee0ee65-97f3-42f3-aa5a-f49f61e17687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to download https://arxiv.org/pdf/1312.464 returned status code 404\n",
      "Attempting to download https://arxiv.org/pdf/2112.02 returned status code 404\n"
     ]
    }
   ],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/\"\n",
    "output_dir = \"fulltexts\"\n",
    "for arxiv_id in arxiv_ml_reviews.arxiv_id:\n",
    "    url = f\"{arxiv_url}{arxiv_id}\"\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    out_path = os.path.join(output_dir, f\"{arxiv_id}.pdf\")\n",
    "    if not os.path.isfile(out_path):\n",
    "        if r.status_code != 404:\n",
    "            with open(out_path, 'wb') as outfile:\n",
    "                outfile.write(r.content)\n",
    "        else:\n",
    "            print(f\"Attempting to download {arxiv_url}{arxiv_id} returned status code {r.status_code}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08b072a8-1c73-4d22-805d-4d18a0a6c41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 PDF files where downloaded\n"
     ]
    }
   ],
   "source": [
    "file_count = len(glob.glob(os.path.join(output_dir, \"*.pdf\")))\n",
    "print(f\"{file_count} PDF files where downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c6de74-1231-45bd-bf3d-47ac5be17b3d",
   "metadata": {},
   "source": [
    "## Atempt to extract text from pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76a0adcb-e927-4272-9680-de29ab70cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Though most of the abstracts in published papers’ are not written in structured style, they are still organized in a potential logic similar to that of structured abstracts’, only the logic is much vaguer. Therefore, researchers could take advantage of this fact and use syntactical analysis techniques to transfer conventional abstracts into structured ones to support further research. This could contribute a lot to the conducting of SLR.A standard structured abstract includes the following five parts: Background, Object, Method, Result and Conclusion.We develop the following structure to represent primary studies. Details are shown in Figure 4. The “Structured abstracts” class is extended with five sub-classes. The dotted circles represent the parts not surveyed in this study. \n",
      "Title\n",
      "Author\n",
      "Full text\n",
      "ReferenceStructuredabstractBackground\n",
      "Objective\n",
      "Method\n",
      "Result\n",
      "ConclusionThingPrimarystudies\n",
      "ReviewProtocol\n",
      "Figure 4. The primary study structure\n",
      "B. Extending SLRONT to COSONTTo demonstrate the value of ontology, we extend SLRONT to more specific version, the COSONT. COSONT is a more detailed ontology aiming at supporting cost estimation systematic literature review. Since the quality of unstructured abstracts is not as good as structured ones, we make a simplification while modeling it so that unstructured abstracts could be converted into structured ones with grammatical and syntactical analysis. We combine the “Object” part of structured abstracts into the “Method” part and combine the “Result” part into the “Conclusion” part. Therefore, five subclasses of structured abstracts are briefed into three subclasses: Background, Method and Conclusion.The main extending work lies in the Method sub-class of structured abstracts. According to the cost estimation SLR of Jorgensen et al. [14], the most common research topic is the introduction and evaluation of methods (with 61% of the papers). The popular methods include Regression, Neural network, Analogy, Expert judgment, Bayesian, etc. Also metrics such as Size and Uncertainty of effort are popular topics. Therefore, we concluded that the most widely concerns of this field are: a) What methods are used; b) What are the metrics adopted; c) In what context the study is launched.  We extend the SLRONT into COSONT based on the above discussions. Details are shown in Figure 5. StructuredabstractBackground\n",
      "Method\n",
      "ConclusionModelAssociationanalysis\n",
      "Statisticallearning\n",
      "Classification\n",
      "Cluster\n",
      "Classicmethods\n",
      "Case study\n",
      "OtherMetric\n",
      "SEfeatures\n",
      "Simpleconclusion\n",
      "Figure 5. COSONT structure\n",
      "For the “Method” class, we build three sub-classes: Model, Metric and SE_feature. Due to the limitation of space, only partial subclasses of “Model” class are presented. We also build a “Simple conclusion” class as the subclass of the“Conclusion” class. This is only an empty structure. COSONT needs to be instantiated through analyzing the abstracts of papers.\n",
      "Figure 6. The Instantiated COSONT\n",
      "Proceedings of the EASE 2012 - Published by the IETISBN 978-1-84919-541-6 173\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "with open(\"fulltexts/1609.08049.pdf\", \"rb\") as pdf_file:\n",
    "    read_pdf = PyPDF2.PdfFileReader(pdf_file)\n",
    "    number_of_pages = read_pdf.getNumPages()\n",
    "    page = read_pdf.pages[2]\n",
    "    page_content = page.extractText()\n",
    "print(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68617316-e5f4-48b5-8097-d905d1973ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
