{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7298c2de-5a5e-4341-aced-87d957bd12b6",
   "metadata": {},
   "source": [
    "# Load metadata\n",
    "\n",
    "arXiv.org submitters. (2024). arXiv Dataset [Data set]. Kaggle. https://doi.org/10.34740/KAGGLE/DSV/7548853\n",
    "\n",
    "* Download the data manually, put it in folder `data`.\n",
    "* Keep only abstracts and comments\n",
    "* Load all the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10bb65ae-7df9-4dca-be63-e9bfbc3cd1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file\n",
      "Processed 100000 / 2412624 lines\n",
      "Processed 200000 / 2412624 lines\n",
      "Processed 300000 / 2412624 lines\n",
      "Processed 400000 / 2412624 lines\n",
      "Processed 500000 / 2412624 lines\n",
      "Processed 600000 / 2412624 lines\n",
      "Processed 700000 / 2412624 lines\n",
      "Processed 800000 / 2412624 lines\n",
      "Processed 900000 / 2412624 lines\n",
      "Processed 1000000 / 2412624 lines\n",
      "Processed 1100000 / 2412624 lines\n",
      "Processed 1200000 / 2412624 lines\n",
      "Processed 1300000 / 2412624 lines\n",
      "Processed 1400000 / 2412624 lines\n",
      "Processed 1500000 / 2412624 lines\n",
      "Processed 1600000 / 2412624 lines\n",
      "Processed 1700000 / 2412624 lines\n",
      "Processed 1800000 / 2412624 lines\n",
      "Processed 1900000 / 2412624 lines\n",
      "Processed 2000000 / 2412624 lines\n",
      "Processed 2100000 / 2412624 lines\n",
      "Processed 2200000 / 2412624 lines\n",
      "Processed 2300000 / 2412624 lines\n",
      "Processed 2400000 / 2412624 lines\n",
      "CPU times: user 13min 47s, sys: 11 s, total: 13min 58s\n",
      "Wall time: 13min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "frames = []\n",
    "max_bytes = -1  # 1024 * 1024 * 10  # max bytes to read from file\n",
    "# one json per line\n",
    "with open('data/arxiv-metadata-oai-snapshot.json') as json_file:    \n",
    "    print(\"Reading file\")\n",
    "    lines = json_file.readlines(max_bytes)\n",
    "    line_count = len(lines)\n",
    "    counter = 0\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        frames.append(pd.json_normalize(data)[['id', 'abstract', 'comments']])\n",
    "        counter += 1\n",
    "        if counter % 100000 == 0: print(f\"Processed {counter} / {line_count} lines\")\n",
    "arxiv_df = pd.concat(frames, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b57e224-66f2-4549-abe2-4dc8d5d075f9",
   "metadata": {},
   "source": [
    "## Save as compressed CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d606b5-f662-420a-8e3a-35e77fda299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "\n",
    "with zf.ZipFile('data/arxiv_abstracts.csv.zip', 'w') as ziparchive:\n",
    "    ziparchive.writestr('arxiv_abstracts.csv', arxiv_df.to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f5bd5-f83d-4c81-aadc-1199a5cbbd23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
