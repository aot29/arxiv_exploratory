{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c32a6019-86d2-4516-9750-2ded9339c248",
   "metadata": {},
   "source": [
    "# Label and describe using an LLM\n",
    "\n",
    "Download and instantiate an LLM from Huggingface.\n",
    "\n",
    "Load the LDA topic models. \n",
    "\n",
    "Prompt the LLM to generate a label and a description for each topic in the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "624a770b-cedd-4e31-887b-acc692a3b988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/kobv/atroncos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253401c-3595-40eb-9968-9a5d6628a8b9",
   "metadata": {},
   "source": [
    "Load the topic models fitted in a previous notebook.\n",
    "\n",
    "* lda_gw: Gravitational Waves topics\n",
    "* lda_cscl: Computation and Language topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542421d1-a7ff-4cf6-a4e1-9b9cff4ecf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/lda_gw.pickle', 'rb') as handle:\n",
    "    lda_gw = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64b0ca-dbb5-41c0-9381-3a163f4341e6",
   "metadata": {},
   "source": [
    "Get a list of all topics in the model, each topic described by MAX_WORDS \n",
    "\n",
    "* The result is a list of topics. Each topic is represented by a tuple.\n",
    "* The first element of the tuple is a topic number (int).\n",
    "* The second element of the tuple is a list of tuples,\n",
    "* Each tuple represents the words characterising he topic (string) and its corresponding probability (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85b7775-3cd3-4610-982c-4f1ffa5be5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 30\n",
    "# list[tuples<int, list[tuple<string, float>]>]\n",
    "topics_gw = lda_gw.show_topics(num_words=MAX_WORDS, formatted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edbcd20-4cb4-491c-bfe0-5eb1ca4ad227",
   "metadata": {},
   "source": [
    "### Using gated models\n",
    "\n",
    "1. Go to huggingface, login, go to `settings/access tokens` \n",
    "2. Create a new READ token, save it to ../token.txt\n",
    "3. Go here: https://huggingface.co/mistralai/Mistral-7B-v0.1 and accept the usage conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a255ab19-9ca0-46e8-ac85-127f1eddec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/kobv/atroncos/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "with open('../token.txt', 'r') as handle:\n",
    "    token = handle.read()\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95683a43-5540-4701-9dd2-b2ea7650dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_str(topic, max=None):\n",
    "    \"\"\"Return the terms describing a topic as a string\n",
    "    topic: list of tuples<string, float>\n",
    "    \"\"\"\n",
    "    if not max:\n",
    "        resp = ', '.join([term[0] for term in topic[1]])\n",
    "    else:\n",
    "        resp = ', '.join([term[0] for term in topic[1][:max]])    \n",
    "    return(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7c22d7f-ab42-4f45-a7b6-c23fa717664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from accelerate import disk_offload\n",
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Promptable(ABC):\n",
    "    @abstractmethod\n",
    "    def one_shot(self, prompt): pass\n",
    "\n",
    "class Mistral(Promptable):\n",
    "    def __init__(self):\n",
    "        self.model_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "#        self.model = AutoModelForCausalLM.from_pretrained(self.model_id, torch_dtype=torch.float16, low_cpu_mem_usage = False)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(self.model_id, torch_dtype=torch.float16, device_map = 'auto')\n",
    "#        disk_offload(model=self.model, offload_dir=\"alpha\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_id)\n",
    "    \n",
    "    def one_shot(self, prompt):\n",
    "        model_inputs = self.tokenizer([prompt], return_tensors='pt').to('cuda')\n",
    "#        model_inputs = model_inputs.to('meta')\n",
    "#        generated_ids = self.model.generate(**model_inputs, pad_token_id=self.tokenizer.eos_token_id, max_new_tokens=25, do_sample=True)\n",
    "        generated_ids = self.model.generate(**model_inputs, pad_token_id=self.tokenizer.eos_token_id, max_new_tokens=10, do_sample=False, num_beams=1)\n",
    "        decoded_outputs = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        resp = nltk.sent_tokenize(decoded_outputs.strip())[2]  # split into sentences\n",
    "        resp = re.sub(r'[^A-Za-z0-9 ]+', '', resp)  # remove non-alphanumeric chars\n",
    "        return(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "525b21e7-be0e-4ffe-b2b9-ef437ea33d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_topic_labels(category, topics, model):\n",
    "    \"\"\"\n",
    "    Predict label for a list of topics.\n",
    "\n",
    "    category: an arxiv category, see https://arxiv.org/category_taxonomy, e.g. \"General Relativity and Quantum Cosmology\"\n",
    "    topics: topics in an LDA model, obtained through lda_XX.show_topics(num_words=MAX_WORDS, formatted=False)\n",
    "    model: Object implementing abstract class \"Promptable\" (see above)\n",
    "    returns: dataFrame with columns: topic id, label\n",
    "    \"\"\"\n",
    "    topics_range = [topic[0] for topic in topics]\n",
    "    topic_labels = []\n",
    "    topic_ids = []\n",
    "    resp = []\n",
    "    for topic_id in topics_range:\n",
    "        print(f\"Processing topic {topic_id} / {len(topics_range)}\")\n",
    "        terms = get_topic_str(topics[topic_id]) # all keywords, as string\n",
    "        prompt = f\"What concise and human-readable label best describes the topic in the \\\"{category}\\\" category characterized by these terms: {terms}? Output only the label.\"\n",
    "        label = model.one_shot(prompt)\n",
    "        topic_labels.append(label)  # topic label, string, generated by LLM\n",
    "        topic_ids.append(topic_id)  # topic id, numeric\n",
    "        topic_main_words = get_topic_str(topics[topic_id], 5) # the first 5 keywords, as string\n",
    "    return(pd.DataFrame.from_dict({'topic': topic_ids, 'first 5 keywords': topic_main_words, 'label': topic_labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fc64b9a-f9dd-4c94-bd92-811f2f0c96bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.31it/s]\n",
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 0 / 4\n",
      "Processing topic 1 / 4\n",
      "Processing topic 2 / 4\n",
      "Processing topic 3 / 4\n",
      "CPU times: user 2min 31s, sys: 5 s, total: 2min 36s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mistral = Mistral()\n",
    "topics_gw_df = predict_topic_labels(\"General Relativity and Quantum Cosmology\", topics_gw, mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "045f7278-6ffc-4ddb-9185-d30f833b02bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>first 5 keywords</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>field, theory, mode, gravity, equation</td>\n",
       "      <td>Gravitational Wave Detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>field, theory, mode, gravity, equation</td>\n",
       "      <td>Binary Black Hole Merger The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>field, theory, mode, gravity, equation</td>\n",
       "      <td>Dark Energy and Inflation Model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>field, theory, mode, gravity, equation</td>\n",
       "      <td>General Relativity and Quantum Gravity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                        first 5 keywords  \\\n",
       "0      0  field, theory, mode, gravity, equation   \n",
       "1      1  field, theory, mode, gravity, equation   \n",
       "2      2  field, theory, mode, gravity, equation   \n",
       "3      3  field, theory, mode, gravity, equation   \n",
       "\n",
       "                                    label  \n",
       "0            Gravitational Wave Detection  \n",
       "1            Binary Black Hole Merger The  \n",
       "2         Dark Energy and Inflation Model  \n",
       "3  General Relativity and Quantum Gravity  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "topics_gw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0549ff06-e383-484c-9dbd-94f7276fe26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>first 5 keywords</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>field, theory, mode, gravity, equation</td>\n",
       "      <td>Gravitational Wave Detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>field, theory, mode, gravity, equation</td>\n",
       "      <td>Binary Black Hole Merger The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>field, theory, mode, gravity, equation</td>\n",
       "      <td>Dark Energy and Inflation Model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>field, theory, mode, gravity, equation</td>\n",
       "      <td>General Relativity and Quantum Gravity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                        first 5 keywords  \\\n",
       "0      0  field, theory, mode, gravity, equation   \n",
       "1      1  field, theory, mode, gravity, equation   \n",
       "2      2  field, theory, mode, gravity, equation   \n",
       "3      3  field, theory, mode, gravity, equation   \n",
       "\n",
       "                                    label  \n",
       "0            Gravitational Wave Detection  \n",
       "1            Binary Black Hole Merger The  \n",
       "2         Dark Energy and Inflation Model  \n",
       "3  General Relativity and Quantum Gravity  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "topics_gw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de38d0-24b6-4803-9a51-39cffead22d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
