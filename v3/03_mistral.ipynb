{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c32a6019-86d2-4516-9750-2ded9339c248",
   "metadata": {},
   "source": [
    "# Label and describe using an LLM\n",
    "\n",
    "Download and instantiate an LLM from Huggingface.\n",
    "\n",
    "Load the LDA topic models. \n",
    "\n",
    "Prompt the LLM to generate a label and a description for each topic in the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "624a770b-cedd-4e31-887b-acc692a3b988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/kobv/atroncos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253401c-3595-40eb-9968-9a5d6628a8b9",
   "metadata": {},
   "source": [
    "Load the topic models fitted in a previous notebook.\n",
    "\n",
    "* lda_gw: Gravitational Waves topics\n",
    "* lda_cscl: Computation and Language topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542421d1-a7ff-4cf6-a4e1-9b9cff4ecf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA gravitational waves model\n",
    "with open('../models/lda_gw.pickle', 'rb') as handle:\n",
    "    lda_gw = pickle.load(handle)\n",
    "\n",
    "# Ensemble LDA gravitational waves model\n",
    "with open('../models/ensemble_gw.pickle', 'rb') as handle:\n",
    "    ensemble_gw = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bcb16c7-9f47-4f01-a50b-6377b500a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA computing & language model\n",
    "with open('../models/lda_cscl.pickle', 'rb') as handle:\n",
    "    lda_cscl = pickle.load(handle)\n",
    "\n",
    "# Ensemble LDA computing & language model\n",
    "with open('../models/ensemble_cscl.pickle', 'rb') as handle:\n",
    "    ensemble_cscl = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64b0ca-dbb5-41c0-9381-3a163f4341e6",
   "metadata": {},
   "source": [
    "Get a list of all topics in the model, each topic described by MAX_WORDS \n",
    "\n",
    "* The result is a list of topics. Each topic is represented by a tuple.\n",
    "* The first element of the tuple is a topic number (int).\n",
    "* The second element of the tuple is a list of tuples,\n",
    "* Each tuple represents the words characterising he topic (string) and its corresponding probability (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85b7775-3cd3-4610-982c-4f1ffa5be5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 30\n",
    "\n",
    "# The expected format for the topics list is:\n",
    "# list[tuples<int, list[tuple<string, float>]>]\n",
    "\n",
    "# a Gensim LDA model\n",
    "topics_gw = lda_gw.show_topics(num_words=MAX_WORDS, formatted=False)\n",
    "\n",
    "# an Ensemble lDA model, has to be converted to Gensim LDA first\n",
    "topics_ensemble_gw = ensemble_gw.generate_gensim_representation().show_topics(num_topics=-1, num_words=MAX_WORDS, formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0ef802a-40b7-463a-bae7-ae3b3cbba172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a Gensim LDA model\n",
    "topics_cscl = lda_cscl.show_topics(num_words=MAX_WORDS, formatted=False)\n",
    "\n",
    "# an Ensemble lDA model, has to be converted to Gensim LDA first\n",
    "topics_ensemble_cscl = ensemble_cscl.generate_gensim_representation().show_topics(num_topics=-1, num_words=MAX_WORDS, formatted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edbcd20-4cb4-491c-bfe0-5eb1ca4ad227",
   "metadata": {},
   "source": [
    "### Using Llama gated model\n",
    "\n",
    "1. Go to huggingface, login, go to `settings/access tokens` \n",
    "2. Create a new READ token, save it to ../token.txt\n",
    "3. Go here: https://huggingface.co/meta-llama/Meta-Llama-3.1-8Band accept the usage conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a255ab19-9ca0-46e8-ac85-127f1eddec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/kobv/atroncos/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "with open('../token.txt', 'r') as handle:\n",
    "    token = handle.read()\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95683a43-5540-4701-9dd2-b2ea7650dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_str(topic, max=None):\n",
    "    \"\"\"Return the terms describing a topic as a string\n",
    "    topic: list of tuples<string, float>\n",
    "    \"\"\"\n",
    "    if not max:\n",
    "        resp = ', '.join([term[0] for term in topic[1]])\n",
    "    else:\n",
    "        resp = ', '.join([term[0] for term in topic[1][:max]])    \n",
    "    return(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab5732c-490d-4522-9352-a306f994e63c",
   "metadata": {},
   "source": [
    "An wrapper class for the Llama LLM: https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7c22d7f-ab42-4f45-a7b6-c23fa717664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Promptable(ABC):\n",
    "    @abstractmethod\n",
    "    def predict_label(self, category, terms): pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict_description(self, category, terms): pass\n",
    "\n",
    "class Mistral(Promptable):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "    def predict_label(self, category, terms):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"You are an AI assistant specialised in {category}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"What short, concise and human-readable label best describes the topic characterised by these terms: {terms}? Output only the label\"},\n",
    "        ]\n",
    "        outputs = self.pipeline(\n",
    "            messages,\n",
    "            max_new_tokens=25,\n",
    "        )\n",
    "        resp = outputs[0][\"generated_text\"][-1]['content']\n",
    "        resp = re.sub(r'[\\n]+', ' ', resp)  # replace newlines with spaces\n",
    "        resp = re.sub(r'[^A-Za-z0-9 \\-\\.:()]+', '', resp)  # remove non-alphanumeric chars except space, hyphen, dot, column\n",
    "        resp = re.split('\\.|:', resp)[0] # split into sentences, take first one\n",
    "        return resp.title()\n",
    "    \n",
    "    def predict_description(self, category, terms):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"You are an AI assistant specialised in {category}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"What best describes the topic characterised by these terms: {terms}?\"},\n",
    "        ]\n",
    "        outputs = self.pipeline(\n",
    "            messages,\n",
    "            max_new_tokens=256,\n",
    "        )\n",
    "        return outputs[0][\"generated_text\"][-1]['content']\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.pipeline = transformers.pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model_id,\n",
    "            model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "            device_map=\"auto\",\n",
    "            temperature=0.1,\n",
    "            do_sample=True\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        del self.pipeline\n",
    "        # release GPU memory\n",
    "        gc.collect()  # explicitly call garbage collector\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43548260-9101-4a32-9b44-802f17cb5ceb",
   "metadata": {},
   "source": [
    "A function to create labels for all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "525b21e7-be0e-4ffe-b2b9-ef437ea33d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_topic_labels(category, topics, model):\n",
    "    \"\"\"\n",
    "    Predict label for a list of topics.\n",
    "\n",
    "    category: an arxiv category, see https://arxiv.org/category_taxonomy, e.g. \"General Relativity and Quantum Cosmology\"\n",
    "    topics: topics in an LDA model, obtained through lda_XX.show_topics(num_words=MAX_WORDS, formatted=False)\n",
    "    model: Object implementing abstract class \"Promptable\" (see above)\n",
    "    returns: dataFrame with columns: topic id, label\n",
    "    \"\"\"\n",
    "    topic_labels = []  # topic label, string, generated by LLM\n",
    "    topic_ids = []  # topic id, numeric\n",
    "    topic_main_words = []  # the first 5 keywords, as string\n",
    "    topic_descriptions = []  # description of a topic\n",
    "    \n",
    "    topics_range = [topic[0] for topic in topics]\n",
    "    for count, topic in enumerate(topics):\n",
    "        print(f\"Processing topic {count} / {len(topics_range)}\")\n",
    "        topic_id = topic[0]\n",
    "        terms = get_topic_str(topic) # all keywords, as string\n",
    "\n",
    "        # label\n",
    "        label = model.predict_label(category, terms)\n",
    "        topic_labels.append(label)\n",
    "\n",
    "        # numeric topic id\n",
    "        topic_ids.append(topic_id)\n",
    "\n",
    "        # topic keywords\n",
    "        topic_main_words.append(get_topic_str(topic, 5))\n",
    "\n",
    "        # description\n",
    "#        prompt = f\"Describe the topic in the \\\"{category}\\\" category characterised by these terms: {terms}.\"\n",
    "#        description = model.predict_description(category, terms)\n",
    "#        topic_descriptions.append(description)\n",
    "    return(pd.DataFrame.from_dict({'Topic': topic_ids, 'First 5 keywords': topic_main_words, 'Label': topic_labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff7b5d4-9506-448d-80b1-117f08329741",
   "metadata": {},
   "source": [
    "### Topics for Gravitational Waves LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f884b8c-41a3-4f4f-aa78-d669192e0279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.74it/s]\n",
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 0 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 2 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 3 / 4\n",
      "CPU times: user 2min 9s, sys: 3.08 s, total: 2min 12s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with Mistral() as model:\n",
    "    topics_gw_df = predict_topic_labels(\"General Relativity and Quantum Cosmology\", topics_gw, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "045f7278-6ffc-4ddb-9185-d30f833b02bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>First 5 keywords</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>detector, signal, data, noise, frequency</td>\n",
       "      <td>Advanced Gravitational Wave Detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>binary, hole, mass, black, star</td>\n",
       "      <td>Black Hole Binary Merger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>model, spectrum, energy, dark, background</td>\n",
       "      <td>Cosmological Dark Matter And Inflationary Power Spectrum (Cdm-Ips) Explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>field, theory, mode, gravity, equation</td>\n",
       "      <td>General Relativity And Quantum Gravity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic                           First 5 keywords  \\\n",
       "0      0   detector, signal, data, noise, frequency   \n",
       "1      1            binary, hole, mass, black, star   \n",
       "2      2  model, spectrum, energy, dark, background   \n",
       "3      3     field, theory, mode, gravity, equation   \n",
       "\n",
       "                                                                             Label  \n",
       "0                                            Advanced Gravitational Wave Detection  \n",
       "1                                                         Black Hole Binary Merger  \n",
       "2   Cosmological Dark Matter And Inflationary Power Spectrum (Cdm-Ips) Explanation  \n",
       "3                                           General Relativity And Quantum Gravity  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_gw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc564cd-e119-405f-83de-4792126faf0d",
   "metadata": {},
   "source": [
    "### Topics for Gravitational Waves ensemble LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96de38d0-24b6-4803-9a51-39cffead22d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.87it/s]\n",
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 0 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 1 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 2 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 3 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 4 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 5 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 6 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 7 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 8 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 9 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 10 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 11 / 12\n",
      "CPU times: user 6min 25s, sys: 6.72 s, total: 6min 31s\n",
      "Wall time: 6min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with Mistral() as model:\n",
    "    topics_ensemble_gw = predict_topic_labels(\"General Relativity and Quantum Cosmology\", topics_ensemble_gw, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "835d7149-8b8d-45b6-8a64-98fcc3cff298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>First 5 keywords</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hole, black, binary, mass, spin</td>\n",
       "      <td>Black Hole Binaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>search, signal, detector, data, ligo</td>\n",
       "      <td>Gravitational Wave Detection With Ligo-Virgo Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pulsar, timing, array, noise, data</td>\n",
       "      <td>Pulsar Timing Array Pta Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>star, neutron, merger, mass, binary</td>\n",
       "      <td>Compact Star Mergers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mode, star, instability, frequency, neutron</td>\n",
       "      <td>Rotating Neutron Star Instability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>ray, gamma, burst, energy, emission</td>\n",
       "      <td>Short-Duration Gamma-Ray Burst Grb Source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>binary, source, distance, parameter, mass</td>\n",
       "      <td>Binary Black Hole Merger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>theory, gravity, general, scalar, field</td>\n",
       "      <td>Modified Scalar-Tensor Theory Of Gravity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>model, dark, spectrum, inflation, matter</td>\n",
       "      <td>Inflationary Dark Matter-Energy Spectrum Idmesexplanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>transition, phase, model, order, electroweak</td>\n",
       "      <td>Electroweak Phase Transition In The Early Universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>noise, detector, interferometer, frequency, sensitivity</td>\n",
       "      <td>Advanced Quantum Gravity Interferometry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>string, cosmic, model, energy, loop</td>\n",
       "      <td>Cosmic String Model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic                                         First 5 keywords  \\\n",
       "0       0                          hole, black, binary, mass, spin   \n",
       "1       1                     search, signal, detector, data, ligo   \n",
       "2       2                       pulsar, timing, array, noise, data   \n",
       "3       3                      star, neutron, merger, mass, binary   \n",
       "4       4              mode, star, instability, frequency, neutron   \n",
       "5       5                      ray, gamma, burst, energy, emission   \n",
       "6       6                binary, source, distance, parameter, mass   \n",
       "7       7                  theory, gravity, general, scalar, field   \n",
       "8       8                 model, dark, spectrum, inflation, matter   \n",
       "9       9             transition, phase, model, order, electroweak   \n",
       "10     10  noise, detector, interferometer, frequency, sensitivity   \n",
       "11     11                      string, cosmic, model, energy, loop   \n",
       "\n",
       "                                                         Label  \n",
       "0                                          Black Hole Binaries  \n",
       "1         Gravitational Wave Detection With Ligo-Virgo Network  \n",
       "2                             Pulsar Timing Array Pta Analysis  \n",
       "3                                         Compact Star Mergers  \n",
       "4                            Rotating Neutron Star Instability  \n",
       "5                    Short-Duration Gamma-Ray Burst Grb Source  \n",
       "6                                     Binary Black Hole Merger  \n",
       "7                     Modified Scalar-Tensor Theory Of Gravity  \n",
       "8    Inflationary Dark Matter-Energy Spectrum Idmesexplanation  \n",
       "9           Electroweak Phase Transition In The Early Universe  \n",
       "10                     Advanced Quantum Gravity Interferometry  \n",
       "11                                         Cosmic String Model  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_ensemble_gw.sort_values(by='Topic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b6fa28-7972-4de2-b603-61bf04fba542",
   "metadata": {},
   "source": [
    "### Topics Computing & Language LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb66d4e4-b4c4-4818-86be-c2b8b57c8064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.71it/s]\n",
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 0 / 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 1 / 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 2 / 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 3 / 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 4 / 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 5 / 6\n",
      "CPU times: user 3min 14s, sys: 4.2 s, total: 3min 18s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with Mistral() as model:\n",
    "    topics_cscl_df = predict_topic_labels(\"Computation and Language\", topics_cscl, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d9efad7-57e0-4050-bf26-a59034ec899f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>First 5 keywords</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>data, research, user, analysis, text</td>\n",
       "      <td>Data-Driven Text Analysis For Social Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>task, data, training, performance, learning</td>\n",
       "      <td>Machine Learning Model Training And Performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>question, llm, human, knowledge, task</td>\n",
       "      <td>Natural Language Question Answering System (Nlqas) With Large Datasets And Human-Like Performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>translation, speech, english, data, machine</td>\n",
       "      <td>Multilingual Neural Machine Translation (Speech-To-Text And Text-To-Text) With Error Cor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>word, based, method, sentence, representation</td>\n",
       "      <td>Semantic Sentence Representation Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>image, text, speech, visual, feature</td>\n",
       "      <td>Multimodal Computation And Language Processing (Mclp) Explanation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic                               First 5 keywords  \\\n",
       "0      0           data, research, user, analysis, text   \n",
       "1      1    task, data, training, performance, learning   \n",
       "2      2          question, llm, human, knowledge, task   \n",
       "3      3    translation, speech, english, data, machine   \n",
       "4      4  word, based, method, sentence, representation   \n",
       "5      5           image, text, speech, visual, feature   \n",
       "\n",
       "                                                                                                Label  \n",
       "0                                                          Data-Driven Text Analysis For Social Media  \n",
       "1                                                     Machine Learning Model Training And Performance  \n",
       "2   Natural Language Question Answering System (Nlqas) With Large Datasets And Human-Like Performance  \n",
       "3            Multilingual Neural Machine Translation (Speech-To-Text And Text-To-Text) With Error Cor  \n",
       "4                                                           Semantic Sentence Representation Learning  \n",
       "5                                   Multimodal Computation And Language Processing (Mclp) Explanation  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_cscl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9181a-a0a0-423f-8d13-a1044c84b3e6",
   "metadata": {},
   "source": [
    "### Topics Computing & Language ensemble LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7e21c21-0c9a-4189-adeb-bca686619733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.90it/s]\n",
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 0 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 1 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 2 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 3 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 4 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 5 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 6 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 7 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 8 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 9 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 10 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 11 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 12 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 13 / 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic 14 / 15\n",
      "CPU times: user 7min 46s, sys: 8.16 s, total: 7min 55s\n",
      "Wall time: 7min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with Mistral() as model:\n",
    "    topics_ensemble_cscl = predict_topic_labels(\"Computation and Language\", topics_ensemble_cscl, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df53d667-aff8-4f3f-8ce0-f5f6eae7d9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>First 5 keywords</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>translation, machine, data, nmt, neural</td>\n",
       "      <td>Neural Machine Translation (Nmt) - Training  Performance Explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>question, answer, answering, task, reasoning</td>\n",
       "      <td>Question Answering And Information Retrieval (Qair)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>llm, task, large, performance, prompt</td>\n",
       "      <td>Large-Scale Llm (Language Model) Performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>speech, data, task, recognition, training</td>\n",
       "      <td>Speech Recognition System</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bias, gender, data, task, based</td>\n",
       "      <td>Gender Bias In Large-Scale Nlp Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>dialogue, task, state, system, human</td>\n",
       "      <td>Dialogue System</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>style, knowledge, task, transfer, text</td>\n",
       "      <td>Text-Based Transfer Learning For Sentence-Level Tasks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>evaluation, human, metric, task, summarization</td>\n",
       "      <td>Automatic Text Summarization Evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>topic, approach, document, method, word</td>\n",
       "      <td>Topic Modeling With Neural Lda And Text Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>event, argument, extraction, task, method</td>\n",
       "      <td>Event-Based Argument Mining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>code, task, generation, training, dataset</td>\n",
       "      <td>Machine Learning Model Training And Evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>grammar, parsing, based, syntactic, parser</td>\n",
       "      <td>Natural Language Processing (Nlp) Techniques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>graph, method, word, approach, network</td>\n",
       "      <td>Text-Based Graph Neural Networks For Information Retrieval And Question Answering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>news, social, medium, information, data</td>\n",
       "      <td>Social Media News Detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>speaker, speech, based, method, task</td>\n",
       "      <td>Speech-Based Methods For Multi-Utterance Text Proposal In Human-Voice Prosody Labeling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic                                First 5 keywords  \\\n",
       "0       0         translation, machine, data, nmt, neural   \n",
       "1       1    question, answer, answering, task, reasoning   \n",
       "2       2           llm, task, large, performance, prompt   \n",
       "3       3       speech, data, task, recognition, training   \n",
       "4       4                 bias, gender, data, task, based   \n",
       "5       5            dialogue, task, state, system, human   \n",
       "6       6          style, knowledge, task, transfer, text   \n",
       "7       7  evaluation, human, metric, task, summarization   \n",
       "8       8         topic, approach, document, method, word   \n",
       "9       9       event, argument, extraction, task, method   \n",
       "10     10       code, task, generation, training, dataset   \n",
       "11     11      grammar, parsing, based, syntactic, parser   \n",
       "12     12          graph, method, word, approach, network   \n",
       "13     13         news, social, medium, information, data   \n",
       "14     14            speaker, speech, based, method, task   \n",
       "\n",
       "                                                                                      Label  \n",
       "0                      Neural Machine Translation (Nmt) - Training  Performance Explanation  \n",
       "1                                       Question Answering And Information Retrieval (Qair)  \n",
       "2                                              Large-Scale Llm (Language Model) Performance  \n",
       "3                                                                 Speech Recognition System  \n",
       "4                                                    Gender Bias In Large-Scale Nlp Systems  \n",
       "5                                                                           Dialogue System  \n",
       "6                                     Text-Based Transfer Learning For Sentence-Level Tasks  \n",
       "7                                                   Automatic Text Summarization Evaluation  \n",
       "8                                     Topic Modeling With Neural Lda And Text Data Analysis  \n",
       "9                                                               Event-Based Argument Mining  \n",
       "10                                           Machine Learning Model Training And Evaluation  \n",
       "11                                             Natural Language Processing (Nlp) Techniques  \n",
       "12        Text-Based Graph Neural Networks For Information Retrieval And Question Answering  \n",
       "13                                                              Social Media News Detection  \n",
       "14   Speech-Based Methods For Multi-Utterance Text Proposal In Human-Voice Prosody Labeling  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_ensemble_cscl.sort_values(by='Topic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f982e997-accc-471d-ba09-5d79e51d674f",
   "metadata": {},
   "source": [
    "## Save labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec8ee748-8256-4d36-b028-348062daa897",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_PATH = '../models'\n",
    "topics_ensemble_cscl.to_csv(os.path.join(LABELS_PATH, 'labels_ensemble_cscl.csv'), index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9070246b-5b2a-4135-a144-e033a6c81eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
